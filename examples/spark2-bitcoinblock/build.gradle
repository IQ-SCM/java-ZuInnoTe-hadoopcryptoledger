buildscript {
    repositories  {
        maven {
        url "https://plugins.gradle.org/m2/"
        }
    }
    dependencies {
        classpath 'gradle.plugin.com.github.johnrengelman:shadow:7.1.0'
    }
}

apply plugin: 'com.github.johnrengelman.shadow'
apply plugin: 'java'
apply plugin: 'eclipse'
apply plugin: 'jacoco'
apply plugin: 'application'

compileJava.options.encoding = 'UTF-8'
sourceCompatibility = 1.8
version = '1.0'


shadowJar {
      manifest {
         attributes 'Implementation-Title': 'Example - Spark 2 job (BitcoinBlock) for analysing Bitcoin data using hadoopcryptoledger', 'Implementation-Version': version
       }
    baseName = 'example-hcl-spark2-bitcoinblock'
    version = '0.1.0'
}


mainClassName = "org.zuinnote.spark.bitcoin.example.SparkBitcoinBlockCounter"

repositories {
    mavenCentral()
    mavenLocal()
}


jacocoTestReport {
    reports {
        xml.enabled true
        csv.enabled true
    }
}



configurations {
	provided
	testProvided
	testIntegrationCompile.extendsFrom testCompile
	testIntegrationRuntime.extendsFrom testRuntime
}

eclipse {

  classpath {
    plusConfigurations += [ configurations.provided ]
    plusConfigurations += [ configurations.testProvided ]
    plusConfigurations += [ configurations.testIntegrationCompile ]
	plusConfigurations += [ configurations.testIntegrationRuntime ]
  }
}

sourceSets {
    main.compileClasspath += configurations.provided
    test.compileClasspath += configurations.provided
    test.runtimeClasspath += configurations.provided
    testIntegration {
        java {
            compileClasspath += main.output + test.output + configurations.provided
            runtimeClasspath += main.output + test.output + configurations.provided
            srcDir file('src/integration-test/java')
        }
        resources.srcDir file('src/integration-test/resources')
	}
}

dependencies {

   // spark-core
    compileOnly("org.apache.spark:spark-core_2.11:2.4.8")
   // spark-sql for SparkSession
 compileOnly("org.apache.spark:spark-sql_2.11:2.4.7")
   // hadoop lib for input format
     compileOnly("org.apache.hadoop:hadoop-client:3.3.0")
   // hadoop crypto ledger library
   implementation("com.github.zuinnote:hadoopcryptoledger-fileformat:1.3.2")
        // testing
     testImplementation("org.apache.spark:spark-core_2.11:2.4.8")
     testImplementation group: 'org.junit.jupiter', name: 'junit-jupiter-api', version: '5.8.2'
     testRuntimeOnly group: 'org.junit.jupiter', name: 'junit-jupiter-engine', version: '5.8.2'
    testIntegrationImplementation group: 'org.junit.jupiter', name: 'junit-jupiter-engine', version: '5.8.2'
	testIntegrationRuntimeOnly group: 'org.junit.platform', name: 'junit-platform-console', version: '1.8.2'
    testIntegrationImplementation group: 'javax.servlet', name: 'javax.servlet-api', version: '3.0.1' // need to avoid conflicts with different versions
      testIntegrationImplementation("com.github.zuinnote:hadoopcryptoledger-fileformat:1.3.2")
    testIntegrationImplementation group: 'org.apache.hadoop', name: 'hadoop-minicluster', version: '2.7.0'
testIntegrationImplementation("org.apache.hadoop:hadoop-client:2.7.0")
    testIntegrationImplementation("org.apache.spark:spark-core_2.11:2.4.8")
}

task testIntegration(type: Test) {
    systemProperty "java.awt.headless", "true"
    testClassesDirs = sourceSets.testIntegration.output.classesDirs
    classpath = sourceSets.testIntegration.runtimeClasspath
    useJUnitPlatform()
}

check.dependsOn testIntegration
testIntegration.mustRunAfter test

